<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Clasificador de Flores 🌼</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      background: #f0f8ff;
    }
    h1 {
      font-size: 2.2rem;
      margin-top: 20px;
    }
    #video {
      display: block;
      margin: 20px auto;
      border: 2px solid #aaa;
    }
    #canvas {
      display: none;
    }
    #resultado {
      font-size: 1.4rem;
      font-weight: bold;
      margin-top: 20px;
      color: #2d6a4f;
    }
    button {
      margin-top: 10px;
      padding: 10px 20px;
      font-size: 1rem;
      background-color: #2d6a4f;
      color: white;
      border: none;
      border-radius: 5px;
    }
  </style>
</head>
<body>

  <h1>Clasificador de Flores 🌼</h1>
  <p>Modelo TensorFlow.js (formato graph model)</p>
  
  <video id="video" width="224" height="224" autoplay muted playsinline></video>
  <canvas id="canvas" width="100" height="100"></canvas>
  <h2>Flor detectada: <span id="resultado">...</span></h2>
  <button onclick="cambiarCamara()">Cambiar cámara</button>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.22.0"></script>

  <script>
    const clases = ['dandelion', 'daisy', 'tulips', 'sunflowers', 'roses'];
    const tamano = 224;
    const inputTamano = 100;

    let video = document.getElementById("video");
    let canvas = document.getElementById("canvas");
    let ctx = canvas.getContext("2d");
    let currentStream = null;
    let facingMode = "user";
    let modelo = null;

    async function cargarModelo() {
      console.log("Cargando modelo...");
      modelo = await tf.loadGraphModel("model.json"); // CAMBIO HECHO AQUÍ
      console.log("Modelo cargado.");
    }

    function mostrarCamara() {
      const opciones = {
        audio: false,
        video: {
          width: tamano,
          height: tamano,
          facingMode: facingMode
        }
      };

      if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
        navigator.mediaDevices.getUserMedia(opciones)
          .then(function(stream) {
            currentStream = stream;
            video.srcObject = stream;
            video.play();
            procesarCamara();
            predecir();
          })
          .catch(function(err) {
            alert("No se pudo acceder a la cámara.");
            console.error("Error de cámara:", err);
          });
      } else {
        alert("Tu navegador no soporta getUserMedia");
      }
    }

    function cambiarCamara() {
      if (currentStream) {
        currentStream.getTracks().forEach(track => track.stop());
      }
      facingMode = facingMode === "user" ? "environment" : "user";
      mostrarCamara();
    }

    function procesarCamara() {
      ctx.drawImage(video, 0, 0, inputTamano, inputTamano);
      setTimeout(procesarCamara, 100);
    }

    function predecir() {
      if (modelo) {
        ctx.drawImage(video, 0, 0, inputTamano, inputTamano);
        let imgData = ctx.getImageData(0, 0, inputTamano, inputTamano);
        let gray = [];

        for (let i = 0; i < imgData.data.length; i += 4) {
          let r = imgData.data[i] / 255;
          let g = imgData.data[i + 1] / 255;
          let b = imgData.data[i + 2] / 255;
          let avg = (r + g + b) / 3;
          gray.push(avg);
        }

        let inputTensor = tf.tensor4d(gray, [1, inputTamano, inputTamano, 1]);
        let pred = modelo.predict(inputTensor);
        pred.data().then(data => {
          const index = data.indexOf(Math.max(...data));
          document.getElementById("resultado").innerText = clases[index];
        });

        inputTensor.dispose();
      }

      setTimeout(predecir, 500);
    }

    window.onload = async () => {
      await cargarModelo();
      mostrarCamara();
    };
  </script>

</body>
</html>
